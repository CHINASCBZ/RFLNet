#this code is based on BASNet for RFLNet: Reverse Feature Learning Network for Salient Object Detection in Forward-Looking Sonar Images
# if you have any questions please contact with the author HFL,email ï¼šHFL_CHN@163.com. wechatï¼šH2363050138




import torch   è¿›å£ç«ç‚¬   è¿›å£ç«ç‚¬
import torch.nn as nn   è¿›å£ç«ç‚¬ã€‚Nn as Nn
from torchvision import modelsä»ç«ç‚¬è§†è§‰å¯¼å…¥æ¨¡å‹
import torch.nn.functional as Fè¿›å£ç«ç‚¬ã€‚n.åŠŸèƒ½ä¸ºF
from torchvision.models import ResNet34_Weightsä»torchvisionã€‚modelså¯¼å…¥ResNet34_Weights
from model.resnet_model import *
from torch.nn import functionalä»ç«ç‚¬ã€‚Nnå¯¼å…¥å‡½æ•°

class channelmix(nn.Module):   #å°†ä¸­é—´è¾“å‡ºçš„å›¾ç‰‡ï¼Œç»è¿‡rclå·ç§¯ï¼Œå°†maskè¿›è¡Œè¾“å…¥ï¼Œåœ¨è¿›è¡Œbhsæ¨¡å‹æŸå¤±
    def __init__(self,inchannel,outchannel,scale=4):def __init__(è‡ªæˆ‘ã€inchannel outchannelã€è§„æ¨¡= 4):
        super(channelmix,self).__init__()è¶…çº§(channelmixè‡ªæˆ‘). __init__ ()
        self.scale_channel = int(inchannel/scale)è‡ªæˆ‘ã€‚Scale_channel = intï¼ˆinchannel/scaleï¼‰
        #----------------------------------------ä¸Šä¸‹channelå…¬å…±å·ç§¯------------------------------------------------------#
        self.conv3x3 = nn.Conv2d(in_channels=self.scale_channel,out_channels=self.scale_channel,kernel_size=3,stride=1,padding=1)è‡ªæˆ‘ã€‚conv3x3 = nn.Conv2dï¼ˆin_channels=self.scale_channel,out_channels=self.scale_channel,kernel_size=3,stride=1,padding=1ï¼‰
        self.batchnorm = nn.BatchNorm2d(self.scale_channel)è‡ªæˆ‘ã€‚batchnorm = nn.BatchNorm2dï¼ˆself.scale_channelï¼‰
        self.relu = nn.ReLU(inplace=True)è‡ªæˆ‘ã€‚relu = nn.ReLU(inplace=True)

        #------------------------ä¸Šé¢channelå·ç§¯---------------------------------#
        self.conv3x3_up_1 = nn.Conv2d(in_channels=inchannel,out_channels=outchannel,kernel_size=3,stride=1,padding=1)è‡ªæˆ‘ã€‚Conv3x3_up_1 = nnã€‚Conv2d (in_channels = inchannel out_channels = outchannel kernel_size = 3,è·¨æ­¥= 1,å¡«å……= 1)
        self.batchnorm_up_1 = nn.BatchNorm2d(outchannel)è‡ªæˆ‘ã€‚Batchnorm_up_1 = nnã€‚BatchNorm2d (outchannel)
        self.relu_up_1 = nn.ReLU(inplace=True)è‡ªæˆ‘ã€‚relu_up_1 = nnã€‚å†æ¬¡é˜…è¯»(inplace = True)
        self.conv3x3_up_2 = nn.Conv2d(in_channels=outchannel, out_channels=outchannel, kernel_size=3, stride=1,padding=1)è‡ªæˆ‘ã€‚Conv3x3_up_2 = nnã€‚Conv2dï¼ˆin_channels=outchannel, out_channels=outchannel, kernel_size=3, stride=1,padding=1ï¼‰
        self.batchnorm_up_2 = nn.BatchNorm2d(outchannel)è‡ªæˆ‘ã€‚Batchnorm_up_2 = nnã€‚BatchNorm2d (outchannel)
        self.relu_up_2 = nn.ReLU(inplace=True)è‡ªæˆ‘ã€‚relu_up_2 = nnã€‚å†æ¬¡é˜…è¯»(inplace = True)

        #------------------------ä¸‹é¢channelå·ç§¯-----------------------------------#
        self.conv3x3_down_1 = nn.Conv2d(in_channels=inchannel, out_channels=outchannel,kernel_size=3,stride=1,padding=1)è‡ªæˆ‘ã€‚Conv3x3_down_1 = nnã€‚Conv2d (in_channels = inchannel out_channels = outchannel kernel_size = 3,è·¨æ­¥= 1,å¡«å……= 1)
        self.batchnorm_down_1 = nn.BatchNorm2d(outchannel)è‡ªæˆ‘ã€‚Batchnorm_down_1 = nnã€‚BatchNorm2d (outchannel)
        self.relu_down_1 = nn.ReLU(inplace=True)è‡ªæˆ‘ã€‚relu_down_1 = nnã€‚å†æ¬¡é˜…è¯»(inplace = True)
        self.conv3x3_down_2 = nn.Conv2d(in_channels=outchannel, out_channels=outchannel, kernel_size=3, stride=1,padding=1)è‡ªæˆ‘ã€‚Conv3x3_down_2 = nnã€‚Conv2dï¼ˆin_channels=outchannel, out_channels=outchannel, kernel_size=3, stride=1,padding=1ï¼‰
        self.batchnorm_down_2 = nn.BatchNorm2d(outchannel)è‡ªæˆ‘ã€‚Batchnorm_down_2 = nnã€‚BatchNorm2d (outchannel)
        self.relu_down_2 = nn.ReLU(inplace=True)è‡ªæˆ‘ã€‚relu_down_2 = nnã€‚å†æ¬¡é˜…è¯»(inplace = True)

        #-------------------------ä¸Šä¸‹channelç»“åˆå·ç§¯--------------------------------------------------#
        self.up_down_conv3x3_1 = nn.Conv2d(in_channels=outchannel*2,out_channels=outchannel,kernel_size=3,stride=1,padding=1)è‡ªæˆ‘ã€‚Up_down_conv3x3_1 = nnã€‚Conv2d (in_channels = outchannel * 2, out_channels = outchannel kernel_size = 3,è·¨æ­¥= 1,å¡«å……= 1)
        self.up_down_conv3x3_2 = nn.Conv2d(in_channels=outchannel,out_channels=outchannel,kernel_size=3,stride=1,padding=1)è‡ªæˆ‘ã€‚Up_down_conv3x3_2 = nnã€‚Conv2d (in_channels = outchannel out_channels = outchannel kernel_size = 3,è·¨æ­¥= 1,å¡«å……= 1)
        self.up_down_downsample = nn.Upsample(scale_factor=2,mode="bilinear",align_corners=True)è‡ªæˆ‘ã€‚Up_down_downsample = nnã€‚Upsample (scale_factor = 2,æ¨¡å¼=â€œåŒçº¿æ€§align_corners = True)





    def forward(self,x,y):   defå‘å‰(è‡ªæˆ‘,x, y):
        scale_channel_left = self.scale_channelscale_channel = self.scale_channel
        spx1 = torch.split(x,split_size_or_sections=scale_channel_left,dim=1)Spx1 = torch.splitï¼ˆx,split_size_or_sections=scale_channel_left,dim=1ï¼‰
        channel_left_1, channel_left_2, channel_left_3, channel_left_4 = spx1Channel_left_1, channel_left_2, channel_left_3, channel_left_4 = spx1
        spx2 = torch.split(y, split_size_or_sections=scale_channel_left, dim=1)Spx2 =ç«ç‚¬ã€‚Split ï¼ˆy, split_size_or_sections=scale_channel_left, dim=1ï¼‰
        channel_right_1, channel_right_2, channel_right_3, channel_right_4 = spx2Channel_right_1, channel_right_2, channel_right_3, channel_right_4 = spx2

        #-------------ä¸Šé¢-------------------------#
        channel_left_1 = self.relu(self.batchnorm(self.conv3x3(channel_left_1)))Channel_left_1 = self.relu(self.batchnorm(self.conv3x3(Channel_left_1))))
        channel_left_1 = self.relu(self.batchnorm(self.conv3x3(channel_left_1)))Channel_left_1 = self.relu(self.batchnorm(self.conv3x3(Channel_left_1))))

        channel_left_2 = self.relu(self.batchnorm(self.conv3x3(channel_left_2)))Channel_left_2 = self.relu(self.batchnorm(self.conv3x3(Channel_left_2))))
        channel_left_2 = self.relu(self.batchnorm(self.conv3x3(channel_left_2)))Channel_left_2 = self.relu(self.batchnorm(self.conv3x3(Channel_left_2))))

        channel_right_1 = self.relu(self.batchnorm(self.conv3x3(channel_right_1)))Channel_right_1 = self.relu(self.batchnorm(self.conv3x3(Channel_right_1))))
        channel_right_1 = self.relu(self.batchnorm(self.conv3x3(channel_right_1)))Channel_right_1 = self.relu(self.batchnorm(self.conv3x3(Channel_right_1))))

        channel_right_2 = self.relu(self.batchnorm(self.conv3x3(channel_right_2)))Channel_right_2 = self.relu(self.batchnorm(self.conv3x3(Channel_right_2))))
        channel_right_2 = self.relu(self.batchnorm(self.conv3x3(channel_right_2)))Channel_right_2 = self.relu(self.batchnorm(self.conv3x3(Channel_right_2))))

        L1R1 = channel_left_1*channel_right_1
        L1R2 = channel_left_1*channel_right_2
        L2R1 = channel_left_2*channel_left_1
        L2R2 = channel_left_2*channel_right_2

        #--------------------ä¸Šchannelèåˆ-------------------------------#
        UP = torch.cat((L1R1,L1R2,L2R1,L2R2),dim=1)UP = torch.catï¼ˆ(L1R1,L1R2,L2R1,L2R2),dim=1ï¼‰
        UP = self.relu_up_1(self.batchnorm_up_1(self.conv3x3_up_1(UP)))UP = self.relu_up_1(self.batchnorm_up_1(self.conv3x3_up_1(UP))))
        UP = self.relu_up_2(self.batchnorm_up_2(self.conv3x3_up_2(UP)))UP = self.relu_up_2ï¼ˆself.batchnorm_up_2(self.conv3x3_up_2(UP))ï¼‰





        #------------ä¸‹é¢------------------------------#
        channel_left_3 = self.relu(self.batchnorm(self.conv3x3(channel_left_3)))Channel_left_3 = self.relu(self.batchnorm(self.conv3x3(Channel_left_3))))
        channel_left_3 = self.relu(self.batchnorm(self.conv3x3(channel_left_3)))Channel_left_3 = self.relu(self.batchnorm(self.conv3x3(Channel_left_3))))

        channel_left_4 = self.relu(self.batchnorm(self.conv3x3(channel_left_4)))Channel_left_4 = self.relu(self.batchnorm(self.conv3x3(Channel_left_4))))
        channel_left_4 = self.relu(self.batchnorm(self.conv3x3(channel_left_4)))Channel_left_4 = self.relu(self.batchnorm(self.conv3x3(Channel_left_4))))

        channel_right_3 = self.relu(self.batchnorm(self.conv3x3(channel_right_3)))Channel_right_3 = self.relu(self.batchnorm(self.conv3x3(Channel_right_3))))
        channel_right_3 = self.relu(self.batchnorm(self.conv3x3(channel_right_3)))Channel_right_3 = self.relu(self.batchnorm(self.conv3x3(Channel_right_3))))

        channel_right_4 = self.relu(self.batchnorm(self.conv3x3(channel_right_4)))Channel_right_4 = self.relu(self.batchnorm(self.conv3x3(Channel_right_4))))
        channel_right_4 = self.relu(self.batchnorm(self.conv3x3(channel_right_4)))Channel_right_4 = self.relu(self.batchnorm(self.conv3x3(Channel_right_4))))

        L3R3 = channel_left_3 * channel_right_3
        L3R4 = channel_left_3 * channel_right_4
        L4R3 = channel_left_4 * channel_left_3
        L4R4 = channel_left_4 * channel_right_4

        # --------------------ä¸‹channelèåˆ-------------------------------#
        Down = torch.cat((L3R3,L3R4,L4R3,L4R4),dim=1)Down = torch.catï¼ˆ(L3R3,L3R4,L4R3,L4R4),dim=1ï¼‰
        Down = self.relu_down_1(self.batchnorm_down_1(self.conv3x3_down_1(Down)))Down = self.relu_down_1(self.batchnorm_down_1(self.conv3x3_down_1(Down))))
        Down = self.relu_down_2(self.batchnorm_down_2(self.conv3x3_down_2(Down)))Down = self.relu_down_2ï¼ˆself.batchnorm_down_2(self.conv3x3_down_2(Down))ï¼‰


        #--------------------up_downé€šé“ä¿¡æ¯èåˆ--------------------------------------------#
        up_down = torch.cat((UP,Down),dim=1)
        up_down = self.up_down_conv3x3_1(up_down)
        up_down = self.up_down_conv3x3_2(up_down)
        up_down = self.up_down_downsample(up_down)





        return  up_down

#---------------------------------------Reverse feature extraction module-------------------------------------------------------------------------#
class RFEM(nn.Module):
    def __init__(self,inchannel,outchannel,scale=4):
        super(RFEM,self).__init__()
        self.scale_channel = int(inchannel/scale)
        #----------------------------------------ä¸Šä¸‹channelå…¬å…±å·ç§¯------------------------------------------------------#
        self.conv3x3 = nn.Conv2d(in_channels=self.scale_channel,out_channels=self.scale_channel,kernel_size=3,stride=1,padding=1)
        self.batchnorm = nn.BatchNorm2d(self.scale_channel)
        self.relu = nn.ReLU(inplace=True)

        #------------------------ä¸Šé¢channelå·ç§¯---------------------------------#
        self.conv3x3_up_1 = nn.Conv2d(in_channels=inchannel,out_channels=outchannel,kernel_size=3,stride=1,padding=1)
        self.batchnorm_up_1 = nn.BatchNorm2d(outchannel)
        self.relu_up_1 = nn.ReLU(inplace=True)
        self.conv3x3_up_2 = nn.Conv2d(in_channels=outchannel, out_channels=outchannel, kernel_size=3, stride=1,padding=1)
        self.batchnorm_up_2 = nn.BatchNorm2d(outchannel)
        self.relu_up_2 = nn.ReLU(inplace=True)

        #------------------------ä¸‹é¢channelå·ç§¯-----------------------------------#
        self.conv3x3_down_1 = nn.Conv2d(in_channels=inchannel, out_channels=outchannel,kernel_size=3,stride=1,padding=1)
        self.batchnorm_down_1 = nn.BatchNorm2d(outchannel)
        self.relu_down_1 = nn.ReLU(inplace=True)
        self.conv3x3_down_2 = nn.Conv2d(in_channels=outchannel, out_channels=outchannel, kernel_size=3, stride=1,padding=1)
        self.batchnorm_down_2 = nn.BatchNorm2d(outchannel)
        self.relu_down_2 = nn.ReLU(inplace=True)

        #-------------------------ä¸Šä¸‹channelç»“åˆå·ç§¯--------------------------------------------------#
        self.up_down_conv3x3_1 = nn.Conv2d(in_channels=outchannel*2,out_channels=outchannel,kernel_size=3,stride=1,padding=1)
        self.up_down_conv3x3_2 = nn.Conv2d(in_channels=outchannel,out_channels=outchannel,kernel_size=3,stride=1,padding=1)
        self.up_down_downsample = nn.Upsample(scale_factor=2,mode="bilinear",align_corners=True)





    def forward(self,x,y):
        scale_channel_left = self.scale_channel
        spx1 = torch.split(x,split_size_or_sections=scale_channel_left,dim=1)
        channel_left_1, channel_left_2, channel_left_3, channel_left_4 = spx1
        spx2 = torch.split(y, split_size_or_sections=scale_channel_left, dim=1)
        channel_right_1, channel_right_2, channel_right_3, channel_right_4 = spx2

        #-------------ä¸Šé¢-------------------------#
        channel_left_1 = self.relu(self.batchnorm(self.conv3x3(channel_left_1)))
        channel_left_1 = self.relu(self.batchnorm(self.conv3x3(channel_left_1)))

        channel_left_2 = self.relu(self.batchnorm(self.conv3x3(channel_left_2)))
        channel_left_2 = self.relu(self.batchnorm(self.conv3x3(channel_left_2)))

        channel_right_1 = self.relu(self.batchnorm(self.conv3x3(channel_right_1)))
        channel_right_1 = self.relu(self.batchnorm(self.conv3x3(channel_right_1)))

        channel_right_2 = self.relu(self.batchnorm(self.conv3x3(channel_right_2)))
        channel_right_2 = self.relu(self.batchnorm(self.conv3x3(channel_right_2)))

        L1R1 = channel_left_1*channel_right_1
        L1R2 = channel_left_1*channel_right_2
        L2R1 = channel_left_2*channel_left_1
        L2R2 = channel_left_2*channel_right_2

        #--------------------ä¸Šchannelèåˆ-------------------------------#
        UP = torch.cat((L1R1,L1R2,L2R1,L2R2),dim=1)
        UP = self.relu_up_1(self.batchnorm_up_1(self.conv3x3_up_1(UP)))
        UP = self.relu_up_2(self.batchnorm_up_2(self.conv3x3_up_2(UP)))





        #------------ä¸‹é¢------------------------------#
        channel_left_3 = self.relu(self.batchnorm(self.conv3x3(channel_left_3)))
        channel_left_3 = self.relu(self.batchnorm(self.conv3x3(channel_left_3)))

        channel_left_4 = self.relu(self.batchnorm(self.conv3x3(channel_left_4)))
        channel_left_4 = self.relu(self.batchnorm(self.conv3x3(channel_left_4)))

        channel_right_3 = self.relu(self.batchnorm(self.conv3x3(channel_right_3)))
        channel_right_3 = self.relu(self.batchnorm(self.conv3x3(channel_right_3)))

        channel_right_4 = self.relu(self.batchnorm(self.conv3x3(channel_right_4)))
        channel_right_4 = self.relu(self.batchnorm(self.conv3x3(channel_right_4)))

        L3R3 = channel_left_3 * channel_right_3
        L3R4 = channel_left_3 * channel_right_4
        L4R3 = channel_left_4 * channel_left_3
        L4R4 = channel_left_4 * channel_right_4

        # --------------------ä¸‹channelèåˆ-------------------------------#
        Down = torch.cat((L3R3,L3R4,L4R3,L4R4),dim=1)
        Down = self.relu_down_1(self.batchnorm_down_1(self.conv3x3_down_1(Down)))
        Down = self.relu_down_2(self.batchnorm_down_2(self.conv3x3_down_2(Down)))


        #--------------------up_downé€šé“ä¿¡æ¯èåˆ--------------------------------------------#
        up_down = torch.cat((UP,Down),dim=1)
        up_down = self.up_down_conv3x3_1(up_down)
        up_down = self.up_down_conv3x3_2(up_down)
        up_down = self.up_down_downsample(up_down)





        return  up_down


class channelsplite(nn.Module):   #å°†ä¸­é—´è¾“å‡ºçš„å›¾ç‰‡ï¼Œç»è¿‡rclå·ç§¯ï¼Œå°†maskè¿›è¡Œè¾“å…¥ï¼Œåœ¨è¿›è¡Œbhsæ¨¡å‹æŸå¤±
    def __init__(self,inchannel,outchannel,scale=4):
        super(channelsplite,self).__init__()
        self.scale_channel = int(inchannel / scale)
#--------------------------------------------å·ç§¯æ ¸------------------------------------------------------------------------------------------#
        self.conv_1x1 = nn.Conv2d(in_channels=self.scale_channel,out_channels=self.scale_channel,kernel_size=1,stride=1,padding=0)
        self.conv_3x3 = nn.Conv2d(in_channels=self.scale_channel, out_channels=self.scale_channel, kernel_size=3, stride=1, padding=1)
        self.conv_5x5 = nn.Conv2d(in_channels=self.scale_channel, out_channels=self.scale_channel, kernel_size=5, stride=1, padding=2)
        self.conv_7x7 = nn.Conv2d(in_channels=self.scale_channel, out_channels=self.scale_channel, kernel_size=7, stride=1, padding=3)

    def forward(self, x):
        scale_channel_left = self.scale_channel
        spx1 = torch.split(x, split_size_or_sections=scale_channel_left, dim=1)
        channel_1, channel_2, channel_3, channel_4 = spx1
        channel_1 = self.conv_1x1(channel_1)
        channel_1_2 = channel_1
        channel_2 = self.conv_3x3(channel_2 + channel_1_2)
        channel_2_2 = channel_2
        channel_3 = self.conv_5x5(channel_3 + channel_2_2)
        channel_3_2 = channel_3
        channel_4 = self.conv_7x7(channel_4 + channel_3_2)
        x1 = torch.cat((channel_1, channel_2, channel_3, channel_4), dim=1)  # 1,64,224,224

        return x1

class channelsplite_large_kernel(nn.Module):   #å°†ä¸­é—´è¾“å‡ºçš„å›¾ç‰‡ï¼Œç»è¿‡rclå·ç§¯ï¼Œå°†maskè¿›è¡Œè¾“å…¥ï¼Œåœ¨è¿›è¡Œbhsæ¨¡å‹æŸå¤±
    def __init__(self,inchannel,scale=4):
        super(channelsplite_large_kernel,self).__init__()
        self.scale_channel = int(inchannel / scale)
#--------------------------------------------å·ç§¯æ ¸------------------------------------------------------------------------------------------#
        self.conv_1x1 = nn.Conv2d(in_channels=self.scale_channel, out_channels=self.scale_channel, kernel_size=1,
                                  stride=1, padding=0)
        self.conv_3x3 = nn.Conv2d(in_channels=self.scale_channel, out_channels=self.scale_channel, kernel_size=3,
                                  stride=1, padding=1)
        self.conv_5x5 = nn.Conv2d(in_channels=self.scale_channel, out_channels=self.scale_channel, kernel_size=5,
                                  stride=1, padding=2)
        self.conv_7x7 = nn.Conv2d(in_channels=self.scale_channel, out_channels=self.scale_channel, kernel_size=7,
                                  stride=1, padding=3)

    def forward(self, x):
        scale_channel_left = self.scale_channel
        spx1 = torch.split(x, split_size_or_sections=scale_channel_left, dim=1)
        channel_1, channel_2, channel_3, channel_4 = spx1
        channel_1 = self.conv_1x1(channel_1)
        channel_1_2 = channel_1

        channel_2 = self.conv_3x3(channel_2 + channel_1_2)
        channel_2_2 = channel_2

        channel_3 = self.conv_3x3(channel_3 + channel_2_2)
        channel_3 = self.conv_5x5(channel_3)
        channel_3_2 = channel_3

        channel_4 = self.conv_3x3(channel_4 + channel_3_2)
        channel_4 = self.conv_5x5(channel_4)
        channel_4 = self.conv_7x7(channel_4)

        x1 = torch.cat((channel_1, channel_2, channel_3, channel_4), dim=1)  # 1,64,224,224

        return x1


class RFM(nn.Module):   #Refined Module
    def __init__(self,inchannnels,outchannnels):
        super(RFM,self).__init__()
        self.channelsplite = channelsplite(64,64)
        self.channelsplite2 = channelsplite(128, 128)
        self.channelsplite3 = channelsplite(256, 256)
        self.channelsplite4 = channelsplite(512, 512)
        self.channelsplite5 = channelsplite(1024, 1024)

        self.channelsplite_dialation = channelsplite_large_kernel(64,4)

        self.upsample = nn.Upsample(scale_factor=2,mode="bilinear",align_corners=True)
        self.downsample = nn.MaxPool2d(2,2,ceil_mode=True)
        self.conv00 = nn.Conv2d(in_channels=inchannnels,out_channels=64,kernel_size=3,stride=1,padding=1)
        self.conv01 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1)
        self.conv02 = nn.Conv2d(in_channels=128, out_channels=64, kernel_size=3, stride=1, padding=1)
        self.conv03 = nn.Conv2d(in_channels=64,out_channels=outchannnels,kernel_size=3,stride=1,padding=1)
        self.conv04 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=1, stride=1, padding=0)
        self.conv05 = nn.Conv2d(in_channels=128, out_channels=64, kernel_size=1, stride=1, padding=0)
        self.conv06 = nn.Conv2d(in_channels=inchannnels, out_channels=64, kernel_size=1, stride=1, padding=0)

        self.bn = nn.BatchNorm2d(64)
        self.relu = nn.ReLU(inplace=True)









    def forward(self,x):
        x0 = self.conv00(x)

        #1,64,224,224
        #bolck
        x1 = self.relu(self.bn(self.conv01(x0)))
        x1 = self.channelsplite(x1)    #1,64,224,224
        x1 = self.relu(self.bn(self.conv01(x1)))

        x2 = self.downsample(x1)

        x2 = self.relu(self.bn(self.conv01(x2)))
        x2 = self.channelsplite(x2)
        x2 = self.relu(self.bn(self.conv01(x2)))

        x3 = self.downsample(x2)

        x3 = self.relu(self.bn(self.conv01(x3)))
        x3 = self.channelsplite(x3)
        x3 = self.relu(self.bn(self.conv01(x3)))

        x4 = self.downsample(x3)

        x4 = self.relu(self.bn(self.conv01(x4)))
        x4 = self.channelsplite(x4)  # 28
        x4 = self.relu(self.bn(self.conv01(x4)))

        x5 = self.downsample(x4)

        x5 = self.relu(self.bn(self.conv01(x5))) #14
        x5 = self.channelsplite_dialation(x5)
        x5 = self.relu(self.bn(self.conv01(x5)))

        x6 = self.upsample(x5)
        x6 = torch.cat((x6,x4),dim=1)   #1,128,28,28

        x6 = self.relu(self.bn(self.conv02(x6)))
        x6 = self.channelsplite(x6)
        x6 = self.relu(self.bn(self.conv01(x6)))#64,28,28

        x7 = self.upsample(x6)
        x7 = torch.cat((x7, x3), dim=1)  # 1,128,28,28

        x7 = self.relu(self.bn(self.conv02(x7)))
        x7 = self.channelsplite(x7)
        x7 = self.relu(self.bn(self.conv01(x7)))# 64,56,56

        x8 = self.upsample(x7)
        x8 = torch.cat((x8, x2), dim=1)  # 1,128,112,112

        x8 = self.relu(self.bn(self.conv02(x8)))
        x8 = self.channelsplite(x8)
        x8 = self.relu(self.bn(self.conv01(x8)))# 64,112,112

        x9 = self.upsample(x8)
        x9 = torch.cat((x9, x1), dim=1)  # 1,128,224,224

        x9 = self.relu(self.bn(self.conv02(x9)))
        x9 = self.channelsplite(x9)
        x9 = self.relu(self.bn(self.conv01(x9)))# 64,224,224


        CSM_out = self.conv03(x9)







        # return CSM_out
        return CSM_out +x


class ChannelAttentionModule(nn.Module):
    def __init__(self,channel):
        super(ChannelAttentionModule, self).__init__()

        self.channel_attention_avg = nn.Sequential(
            # nn.AvgPool2d((height, width)),  # å‚æ•°è®¾ç½®ä¸ºè¾“å…¥ç‰¹å¾å›¾çš„é«˜åº¦å’Œå®½åº¦ï¼Œå³256å’Œ256ã€‚è¿™æ„å‘³ç€å¯¹äºæ¯ä¸ªé€šé“ï¼Œæ‰€æœ‰256x256çš„åƒç´ å€¼å°†è®¡ç®—å¹³å‡å€¼ï¼Œç»“æœæ˜¯æ¯ä¸ªé€šé“åªå‰©ä¸‹ä¸€ä¸ªå•ä¸€çš„å¹³å‡å€¼ï¼Œ
            nn.AdaptiveAvgPool2d(1),
            nn.Softmax(dim=1)
        )
        self.channel_attention_max = nn.Sequential(
            nn.AdaptiveMaxPool2d(1),
            nn.Softmax(dim=1)
        )
        self.shared_MLP = nn.Sequential(
            nn.Linear(in_features=channel, out_features=int(channel / 2)),
            nn.ReLU(),
            nn.Linear(in_features=int(channel / 2), out_features=channel)
        )
        self.linear_1 = nn.Linear(in_features=channel,out_features=int(channel/2))
        self.linear_2 = nn.Linear(in_features=int(channel/2),out_features=channel)
        self.relu = nn.ReLU()

    def forward(self, x):
        x_avg_out = self.channel_attention_avg(x)      #1,64,256,256----1,64,1,1
        x_avg = x_avg_out.view(x_avg_out.size(0), -1)   #1,64
        x_avg = self.relu(self.linear_1(x_avg))    #1,32
        x_avg = self.linear_2(x_avg)        #1,64
        x_avg = x_avg.view(x_avg_out.size(0),x_avg_out.size(1),x_avg_out.size(2),x_avg_out.size(3))

        x_max_out = self.channel_attention_max(x)    #1,64,1,1
        x_max = x_max_out.view(x_max_out.size(0),-1)
        x_max = self.relu(self.linear_1(x_max))
        x_max = self.linear_2(x_max)
        x_max = x_max.view(x_max_out.size(0),x_max_out.size(1),x_max_out.size(2),x_max_out.size(3)) #1,64,1,1

        return  x_avg,x_max

class SpatialAttentionModule(nn.Module):
    def __init__(self,):
        super(SpatialAttentionModule, self).__init__()

        self.spatial_attention = nn.Softmax(dim=2)

    def forward(self, x):
        x_spa =x.view([x.size(0), x.size(1), -1])   #1,64,512x512
        x_spa = self.spatial_attention(x_spa)
        x_spa = x_spa.view(x.size(0),x.size(1),x.size(2),x.size(3))

        return  x_spa

class CBPAM(nn.Module):      #CHANNEL SPATIONAL PARALLEL  ATTENTION MODULE
    def __init__(self,channel):
        super(CBPAM, self).__init__()
        self.ChannelAttentionModule = ChannelAttentionModule(channel)
        self.SpatialAttentionModule = SpatialAttentionModule()
        self.signoid = nn.Sigmoid()

    def forward(self,x):
        x_avg,x_max = self.ChannelAttentionModule(x)
        x_spa = self.SpatialAttentionModule(x)

        x_out =self.signoid(x_avg*x_spa+x_avg*x_max)

        return x_out*x


class RFLN(nn.Module):   #å°†æ¨¡å‹ä¸­çš„3x3,csm,3x3ç»“æ„å˜æ¢æˆ 1x1ï¼Œcsm,1x1ç»“æ„
    def __init__(self,n_channels,n_classes):
        super(RFLN,self).__init__()

        resnet = models.resnet34(weights=ResNet34_Weights.DEFAULT)   #ä½¿ç”¨é¢„è®­ç»ƒçš„resnet34æ¥åˆå§‹åŒ–ç¼–è¯‘å™¨å™¨éƒ¨åˆ†
        self.CBPAM5 =CBPAM(512)
        self.CBPAM4 =CBPAM(512)
        self.CBPAM3 =CBPAM(256)
        self.CBPAM2 =CBPAM(128)
        self.CBPAM1 =CBPAM(64)



        ## -------------Encoder--------------

        self.inconv = nn.Conv2d(n_channels,64,3,padding=1)
        self.inbn = nn.BatchNorm2d(64)
        self.inrelu = nn.ReLU(inplace=True)

        #stage 1
        self.encoder1 = resnet.layer1 #224
        #stage 2
        self.encoder2 = resnet.layer2 #112
        #stage 3
        self.encoder3 = resnet.layer3 #56
        #stage 4
        self.encoder4 = resnet.layer4 #28

        self.pool4 = nn.MaxPool2d(2,2,ceil_mode=True)

        #stage 5
        self.resb5_1 = BasicBlock(512,512)
        self.resb5_2 = BasicBlock(512,512)
        self.resb5_3 = BasicBlock(512,512) #14

        self.pool5 = nn.MaxPool2d(2,2,ceil_mode=True)

        #stage 6
        self.resb6_1 = BasicBlock(512,512)
        self.resb6_2 = BasicBlock(512,512)
        self.resb6_3 = BasicBlock(512,512) #7

        ## -------------Bridge--------------

        #stage Bridge
        self.convbg_1 = nn.Conv2d(512,512,3,dilation=2, padding=2) # 7
        self.bnbg_1 = nn.BatchNorm2d(512)
        self.relubg_1 = nn.ReLU(inplace=True)
        self.convbg_m = nn.Conv2d(512,512,3,dilation=2, padding=2)
        self.bnbg_m = nn.BatchNorm2d(512)
        self.relubg_m = nn.ReLU(inplace=True)
        self.convbg_2 = nn.Conv2d(512,512,3,dilation=2, padding=2)
        self.bnbg_2 = nn.BatchNorm2d(512)
        self.relubg_2 = nn.ReLU(inplace=True)

        ## -------------Decoder--------------

        #stage 6d
        self.conv6d_1 = nn.Conv2d(1024,512,3,padding=1) # 16
        self.bn6d_1 = nn.BatchNorm2d(512)
        self.relu6d_1 = nn.ReLU(inplace=True)

        self.conv6d_m = nn.Conv2d(512,512,3,dilation=2, padding=2)###
        self.bn6d_m = nn.BatchNorm2d(512)
        self.relu6d_m = nn.ReLU(inplace=True)

        self.conv6d_2 = nn.Conv2d(512,512,3,dilation=2, padding=2)
        self.bn6d_2 = nn.BatchNorm2d(512)
        self.relu6d_2 = nn.ReLU(inplace=True)

        #stage 5d
        self.conv5d_1 = nn.Conv2d(1024,512,3,padding=1) # 16
        self.bn5d_1 = nn.BatchNorm2d(512)
        self.relu5d_1 = nn.ReLU(inplace=True)

        self.conv5d_m = nn.Conv2d(512,512,3,padding=1)###
        self.bn5d_m = nn.BatchNorm2d(512)
        self.relu5d_m = nn.ReLU(inplace=True)

        self.conv5d_2 = nn.Conv2d(512,512,3,padding=1)
        self.bn5d_2 = nn.BatchNorm2d(512)
        self.relu5d_2 = nn.ReLU(inplace=True)

        #stage 4d
        self.conv4d_1 = nn.Conv2d(1024,512,3,padding=1) # 32
        self.bn4d_1 = nn.BatchNorm2d(512)
        self.relu4d_1 = nn.ReLU(inplace=True)

        self.conv4d_m = nn.Conv2d(512,512,3,padding=1)###
        self.bn4d_m = nn.BatchNorm2d(512)
        self.relu4d_m = nn.ReLU(inplace=True)

        self.conv4d_2 = nn.Conv2d(512,256,3,padding=1)
        self.bn4d_2 = nn.BatchNorm2d(256)
        self.relu4d_2 = nn.ReLU(inplace=True)

        #stage 3d
        self.conv3d_1 = nn.Conv2d(512,256,3,padding=1) # 64
        self.bn3d_1 = nn.BatchNorm2d(256)
        self.relu3d_1 = nn.ReLU(inplace=True)

        self.conv3d_m = nn.Conv2d(256,256,3,padding=1)###
        self.bn3d_m = nn.BatchNorm2d(256)
        self.relu3d_m = nn.ReLU(inplace=True)

        self.conv3d_2 = nn.Conv2d(256,128,3,padding=1)
        self.bn3d_2 = nn.BatchNorm2d(128)
        self.relu3d_2 = nn.ReLU(inplace=True)

        #stage 2d

        self.conv2d_1 = nn.Conv2d(256,128,3,padding=1) # 128
        self.bn2d_1 = nn.BatchNorm2d(128)
        self.relu2d_1 = nn.ReLU(inplace=True)

        self.conv2d_m = nn.Conv2d(128,128,3,padding=1)###
        self.bn2d_m = nn.BatchNorm2d(128)
        self.relu2d_m = nn.ReLU(inplace=True)

        self.conv2d_2 = nn.Conv2d(128,64,3,padding=1)
        self.bn2d_2 = nn.BatchNorm2d(64)
        self.relu2d_2 = nn.ReLU(inplace=True)

        #stage 1d
        self.conv1d_1 = nn.Conv2d(128,64,3,padding=1) # 256
        self.bn1d_1 = nn.BatchNorm2d(64)
        self.relu1d_1 = nn.ReLU(inplace=True)

        self.conv1d_m = nn.Conv2d(64,64,3,padding=1)###
        self.bn1d_m = nn.BatchNorm2d(64)
        self.relu1d_m = nn.ReLU(inplace=True)

        self.conv1d_2 = nn.Conv2d(64,64,3,padding=1)
        self.bn1d_2 = nn.BatchNorm2d(64)
        self.relu1d_2 = nn.ReLU(inplace=True)

        ## -------------Bilinear Upsampling--------------
        self.upscore6 = nn.Upsample(scale_factor=32,mode='bilinear')###
        self.upscore5 = nn.Upsample(scale_factor=16,mode='bilinear')
        self.upscore4 = nn.Upsample(scale_factor=8,mode='bilinear')
        self.upscore3 = nn.Upsample(scale_factor=4,mode='bilinear')
        self.upscore2 = nn.Upsample(scale_factor=2, mode='bilinear')

        ## -------------Side Output--------------
        self.outconvb = nn.Conv2d(512, 1, 3, padding=1)
        self.outconv6 = nn.Conv2d(512, 1, 3, padding=1)
        self.outconv5 = nn.Conv2d(512, 1, 3, padding=1)
        self.outconv4 = nn.Conv2d(256, 1, 3, padding=1)
        self.outconv3 = nn.Conv2d(128, 1, 3, padding=1)
        self.outconv2 = nn.Conv2d(64, 1, 3, padding=1)
        self.outconv_1 = nn.Conv2d(64, 1, 3, padding=1)
        #------------------ç›´æ¥è¾“å‡º------------------------#
        self.outconv_x4 = nn.Conv2d(64,1,1,stride=1,padding=0)
        self.outconv_x3 = nn.Conv2d(128, 1, 1, stride=1, padding=0)
        self.outconv_x2 = nn.Conv2d(256, 1, 1, stride=1, padding=0)
        self.outconv_x1 = nn.Conv2d(512, 1, 1, stride=1, padding=0)
        self.outconv_x0 = nn.Conv2d(in_channels=1,out_channels=1,kernel_size=3,stride=1,padding=1)

        ## -------------Refine Module-------------
        self.RFM = RFM(1,1)

        #-----------------é€šé“èåˆ-----------------------------------#
        self.stage1 = channelmix(512,256)è‡ªæˆ‘ã€‚Stage1 = channelmixï¼ˆ512,256ï¼‰
        self.stage2 = channelmix(256, 128)
        self.stage3 = channelmix(128, 64)
        self.stage4 = channelmix(64, 1)






    def forward(self,x):

        hx = x   Hx = x

        ## -------------Encoder-------------
        hx = self.inconv(hx)
        hx = self.inbn(hx)
        hx = self.inrelu(hx)

        h1 = self.encoder1(hx) # 256
        h2 = self.encoder2(h1) # 128
        h3 = self.encoder3(h2) # 64
        h4 = self.encoder4(h3) # 32

        hx = self.pool4(h4) # 16

        hx = self.resb5_1(hx)
        hx = self.resb5_2(hx)
        h5 = self.resb5_3(hx)

        hx = self.pool5(h5) # 8

        hx = self.resb6_1(hx)
        hx = self.resb6_2(hx)
        h6 = self.resb6_3(hx)


        ## -------------Bridge-------------
        hx = self.relubg_1(self.bnbg_1(self.convbg_1(h6)))
        hx = self.relubg_m(self.bnbg_m(self.convbg_m(hx)))Hx = self.relubg_mï¼ˆself.bnbg_m(self.convbg_m(Hx))ï¼‰
        hbg = self.relubg_2(self.bnbg_2(self.convbg_2(hx))) #1,512,7,7HBG = self.relubg_2ï¼ˆself.bnbg_2(self. bnbg_2)ï¼‰convbg_2 (hx))) # 1512ã€7ã€7

        ## -------------Decoder-------------## ------------- è¯‘ç å™¨ -------------

        hx = self.relu6d_1(self.bn6d_1(self.conv6d_1(torch.cat((hbg,h6),1))))
        hx = self.relu6d_m(self.bn6d_m(self.conv6d_m(hx)))
        hd6 = self.relu6d_2(self.bn6d_2(self.conv6d_2(hx))) #1,512,7,7
        hd6_upsample = self.upscore2(hd6)   #1,512,14,14

        hx = self.upscore2(hd6) # 8 -> 16

        hx = self.relu5d_1(self.bn5d_1(self.conv5d_1(torch.cat((hx,self.CBPAM5(h5)),1))))
        hx = self.relu5d_m(self.bn5d_m(self.conv5d_m(hx)))
        hd5 = self.relu5d_2(self.bn5d_2(self.conv5d_2(hx))) #1,512,14,14

        hx = self.upscore2(hd5) # 16 -> 32

        hx = self.relu4d_1(self.bn4d_1(self.conv4d_1(torch.cat((hx,self.CBPAM4(h4)),1))))
        hx = self.relu4d_m(self.bn4d_m(self.conv4d_m(hx)))
        hd4 = self.relu4d_2(self.bn4d_2(self.conv4d_2(hx))) #1,256,28,28

        hx = self.upscore2(hd4) # 32 -> 64

        hx = self.relu3d_1(self.bn3d_1(self.conv3d_1(torch.cat((hx,self.CBPAM3(h3)),1))))hx = self.relu3d_1(self.bn3d_1(self.conv3d_1(torch.cat((hx,self.CBPAM3(h3))),1))))
        hx = self.relu3d_m(self.bn3d_m(self.conv3d_m(hx)))Hx = self.relu3d_mï¼ˆself.bn3d_m(self.conv3d_m(Hx))ï¼‰
        hd3 = self.relu3d_2(self.bn3d_2(self.conv3d_2(hx))) #1,128,56,56Hd3 = self.relu3d_2ï¼ˆself.bn3d_2ï¼‰conv3d_2 (hx))) # 1128, 56   ğ¶å²,56   ğ¶

        hx = self.upscore2(hd3) # 64 -> 128Hx =è‡ªæˆ‘ã€‚Upscore2 (hd3) # 64 ->

        hx = self.relu2d_1(self.bn2d_1(self.conv2d_1(torch.cat((hx,self.CBPAM2(h2)),1))))hx = self.relu2d_1(self.bn2d_1(self.conv2d_1(torch.cat((hx,self.CBPAM2(h2))),1))))
        hx = self.relu2d_m(self.bn2d_m(self.conv2d_m(hx)))Hx = self.relu2d_mï¼ˆself.bn2d_m(self.conv2d_m(Hx))ï¼‰
        hd2 = self.relu2d_2(self.bn2d_2(self.conv2d_2(hx))) #1,64,112,122Hd2 = self.relu2d_2ï¼ˆself.bn2d_2ï¼‰conv2d_2 (hx))) # 1, 64112122

        hx = self.upscore2(hd2) # 128 -> 256Hx =è‡ªæˆ‘ã€‚Upscore2 (hd2) # 128 -> 256

        hx = self.relu1d_1(self.bn1d_1(self.conv1d_1(torch.cat((hx,self.CBPAM1(h1)),1))))hx = self.relu1d_1(self.bn1d_1(self.conv1d_1(torch.cat((hx,self.CBPAM1(h1))),1)))) .
        hx = self.relu1d_m(self.bn1d_m(self.conv1d_m(hx)))Hx = self.relu1d_mï¼ˆself.bn1d_m(self.conv1d_m(Hx))ï¼‰
        hd1 = self.relu1d_2(self.bn1d_2(self.conv1d_2(hx))) #1,64,224,224Hd1 = self.relu1d_2ï¼ˆself.bn1d_2ï¼‰conv1d_2 (hx))) # 1, 64224224


        # ------------------å±‚ä¿¡æ¯------------------------------------#
        #hbg 1,512,7,7
        #hd6 1,512,7,7   # hd6 1512ã€7ã€7
        #hd5 1,512,14,14   14 # hd5 1512å¹´,14å²
        #hd4 1,256,28,28   28 # hd4 1256å¹´28æ—¥
        #hd3 1,128,56,56   56   ğ¶å²çš„# hd3 1128 56   ğ¶
        #hd2 1,64,112,112   # hd2 1, 64112112


        ## -------------Side Output-------------## -------------ä¾§è¾“å‡º-------------
        # db = self.outconvb(hbg)#1,1,7,7
        # d6 = self.outconv6(hd6)#1,1,7,7
        d5 = self.outconv5(hd5)#1,1,14,14D5 = self.outconv5(hd5)#1,1,14,14
        d4 = self.outconv4(hd4)#1,1,28,28D4 = self.outconv4(hd4)#1,1,28,28
        d3 = self.outconv3(hd3)#1,1,56,56D3 = self.outconv3(hd3)#1,1,56   ğ¶,56   ğ¶
        d2 = self.outconv2(hd2)#1,1,112,112D2 = self.outconv2(hd2)#1,1,112,112
        d1 = self.outconv_1(hd1)   #1,1,224,224,D1 =è‡ªæˆ‘ã€‚1224224å¹´outconv_1 (hd1) # 1,

        #-----------------Reverse feature localization branch module----------------------------##----------------- åå‘åŠŸèƒ½å®šä½åˆ†æ”¯æ¨¡å— ----------------------------#
        stage1 = self.stage1(hd6_upsample,hd5)  #512Stage1 =è‡ªæˆ‘ã€‚stage1 (hd6_upsample hd5) # 512   ğ±â€²
        stage2 = self.stage2(stage1,hd4)    #256é˜¶æ®µ2 =è‡ªæˆ‘ã€‚stage2â€”â€”hd4 stage1 # 256
        stage3 = self.stage3(stage2,hd3)       #128é˜¶æ®µ3 = selfã€‚stage3â€”â€”stage2, hd3 # 128
        stage4 = self.stage4(stage3,hd2)    #1,1,224,224é˜¶æ®µ4 = selfã€‚stage4â€”â€”hd2 stage3 1,1,224,224 #





        ## -------------Refine Module-------------## -------------ç»†åŒ–æ¨¡å—-------------
        dout_cms = self.RFM(d1) #224Dout_cms = selfã€‚RFM (d1) # 224







        return  F.sigmoid(dout_cms),F.sigmoid(d1), F.sigmoid(d2), F.sigmoid(d3), F.sigmoid(d4), F.sigmoid(d5),F.sigmoid(stage4)è¿”å›F.sigmoid (dout_cms), Fã€‚sigmoid(d1)ï¼Œ F.sigmoid(d2)ï¼Œ F.sigmoid(d3)ï¼Œ F.sigmoid(d4)ï¼Œ F.sigmoid(d5)ï¼ŒF.sigmoidï¼ˆstage4ï¼‰

        # return F.sigmoid(dout_cms)# return   è¿”å› F.sigmoidï¼ˆdout_cmsï¼‰
        #è¿”å›çš„æ˜¯8çš„tupleæ•°æ®ç±»å‹çš„å€¼ len(return)


if __name__ == "__main__":   å¦‚æœ__name__ == "__main__":
    x = torch.randn((1, 3, 288,288))X =ç«ç‚¬ã€‚Randn ï¼ˆ(1,3,288,288)ï¼‰
    # y = torch.randn((1, 64, 288, 288))# y =ç«ç‚¬ã€‚Randn ï¼ˆ(1,64,288,288)ï¼‰
    model=RFLN(3,1)   æ¨¡å‹= RFLN (3,1)
    # module = CBPAM(64)   # module = CBPAMï¼ˆ64ï¼‰
    output =model(x)   è¾“å‡º(x) =æ¨¡å‹
    print("=", output[0].size())æ‰“å°(â€œ=â€,è¾“å‡º[0].size ())
    # model = RFLN(n_channels=3, n_classes=1)# model   æ¨¡å‹ = RFLNï¼ˆn_channels=3, n_classes=1ï¼‰

    # è®¡ç®—æ€»å‚æ•°æ•°é‡å’Œå¯è®­ç»ƒå‚æ•°æ•°é‡
    total_params = sum(p.numel() for p in model.parameters())Total_params = sum(pã€‚model   æ¨¡å‹.parametersï¼ˆï¼‰ä¸­pçš„Numel ï¼ˆï¼‰
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)Trainable_params = sum(pã€‚å¦‚æœp.requires_gradï¼Œåˆ™model   æ¨¡å‹.parametersï¼ˆï¼‰ä¸­çš„pä¸ºNumel ï¼ˆï¼‰

    print(f"Total parameters: {total_params}")printï¼ˆfâ€œæ€»å‚æ•°ï¼š{total_params}â€ï¼‰
    print(f"Trainable parameters: {trainable_params}")printï¼ˆfâ€œå¯è®­ç»ƒå‚æ•°ï¼š{trainable_params}â€ï¼‰


